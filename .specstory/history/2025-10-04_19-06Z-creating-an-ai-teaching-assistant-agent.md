<!-- Generated by SpecStory -->

<!-- cursor Session cfadd89b-8e83-4534-bced-d37315d72031 (2025-10-04 19:06Z) -->

# Creating an AI teaching assistant agent (2025-10-04 19:06Z)

_**User (2025-10-04 15:32Z)**_

now let's create an AI agent with OpenAI that is regularly polling our clickhouse connection.

And then is creating a small modal at the top left of the screen to display prompts to the user to give them feedback on what they should do differently.

You can use the below rough agent prompt

"You are playing the role of assistant Teaching Assistant. Your role is to review the stream of student sentiment scores in the chat interface and call out cases where the instructor should slow down or re-review a subject. It should also call out cases where there are students who have strong sentiment that might be worth  calling on to answer questions in class to create engagement or to encourage a student with a weaker student to see if they have questions. It should provide thoughtful prompts of no more than 2 sentences at a time. It should space out its feedback such that it provides feedback every 15 seconds"

---

_**Assistant (gpt-5)**_

<think><details><summary>Thought Process</summary>**Planning UI and API Integration**

I need a UI modal in the top-left to display prompts, plus a polling mechanism to fetch new suggestions every 15 seconds. I'll create an API route, /api/teaching-assistant-suggestions, using OpenAI to transform data into short prompts based on the system prompt while minimizing complexity. I could pull metrics from ClickHouse or existing pulse endpoints. I’ll plan to follow the instructions for multi-step tasks and ensure compliance with coding styles in a Next.js app using TypeScript.
**Setting Up API Routes**

I'm planning to create a new route, either `app/api/ai-teaching-assistant/route.ts` or `app/api/teaching-assistant/route.ts`. I’ll look at the existing test-openai route to understand how to use OpenAI. I also need to see how ClickHouse is accessed in the current routes, so I'll perform a codebase search. At the same time, I want to look for ClickHouse client setup and SQL queries, since pulse routes likely query ClickHouse as well.</details></think>

---

I'll scan the codebase to find how ClickHouse queries and OpenAI are currently implemented so I can add a new API route and a small top-left modal, then wire up a 15-second polling loop.

---

Tool use: **codebase_search**

<details>
                <summary>Searched codebase "Where is ClickHouse queried for pulse/sentiment data? How do we connect to ClickHouse?" • **14** results</summary>
            
| File | Lines |
|------|-------|
| `app/api/pulse/summary/route.ts` | L36 |
| `app/api/pulse/distribution/route.ts` | L33 |
| `app/api/pulse/avg-over-time/route.ts` | L42 |
| `app/api/log-confidence/route.ts` | L3-21 |
| `app/api/pulse/summary/route.ts` | L3-36 |
| `app/api/log-confidence/route.ts` | L93-148 |
| `app/api/pulse/distribution/route.ts` | L3-33 |
| `components/PulseTab.tsx` | L77-249 |
| `app/api/pulse/avg-over-time/route.ts` | L3-42 |
| `app/api/log-confidence/route.ts` | L15 |
| `app/api/log-confidence/route.ts` | L38-148 |
| `README.md` | L34-129 |
| `README.md` | L39 |
| `package.json` | L28 |

</details>

---

Tool use: **codebase_search**

<details>
                <summary>Searched codebase "Where do we call OpenAI in API routes? How is OpenAI client configured?" • **12** results</summary>
            
| File | Lines |
|------|-------|
| `app/api/test-openai/route.ts` | L68 |
| `app/api/log-confidence/route.ts` | L23-105 |
| `app/api/translate-message/route.ts` | L89 |
| `app/api/detect-language/route.ts` | L130 |
| `app/api/generate-student-message/route.ts` | L13-105 |
| `app/api/generate-test-transcript/route.ts` | L90 |
| `app/api/generate-student-message/route.ts` | L105 |
| `app/api/log-confidence/route.ts` | L93-148 |
| `ENV_SETUP.md` | L63 |
| `app/api/translate/route.ts` | L62 |
| `app/api/translate-deepl/route.ts` | L113 |
| `app/api/get-token/route.ts` | L65 |

</details>

---

Tool use: **codebase_search**

<details>
                <summary>Searched codebase "How does the pulse API compute or return sentiment summary or distribution?" • **6** results</summary>
            
| File | Lines |
|------|-------|
| `app/api/pulse/summary/route.ts` | L3-36 |
| `app/api/pulse/distribution/route.ts` | L3-33 |
| `app/api/pulse/summary/route.ts` | L36 |
| `app/api/pulse/distribution/route.ts` | L33 |
| `app/api/pulse/avg-over-time/route.ts` | L3-42 |
| `app/api/pulse/avg-over-time/route.ts` | L42 |

</details>

---

<think><details><summary>Thought Process</summary>**Implementing AI Feedback Loop**

I need to set up an AI agent with OpenAI that polls a ClickHouse connection regularly. It should create a small modal in the top left of the screen to display prompts for user feedback. We already have pulse API endpoints for sentiment info, which could either be reused or a new one created to fetch recent events. I’ll implement a polling loop that calls an endpoint, returning current agent suggestions based on feedback every 15 seconds.
**Developing AI Agent Functionality**

I need to create an AI agent using OpenAI that polls our ClickHouse connection regularly. The server route will query ClickHouse and OpenAI upon each request, providing suggestions to the client every 15 seconds. I'll plan to set up an API route at `app/api/ta-agent/route.ts` that queries data from the last few minutes and computes sentiment triggers per student. The system will use provided prompts to summarize the situation, returning a JSON response with a timestamp and a suggestion. I'll also add a small modal component in the top-left corner for user interaction.
**Integrating Polling Functionality**

I need to set up polling every 15 seconds for the AI agent. I could either integrate this into `Navbar.tsx` or create a new overlay. Since I’m working with a Next.js app, I’ll consider the structure, including `ControlPanel.tsx`. I plan to add a global component in `app/layout.tsx` that will render the overlay across all pages. First, I'll inspect `app/layout.tsx` to figure out the best way to insert this overlay smoothly.</details></think>

---

I'll read the key files to see where to integrate a new overlay component and how the Pulse endpoints are structured to reuse ClickHouse. Then I'll add a new API route that queries ClickHouse and OpenAI, and a React component that polls it every 15s and shows a top-left modal.

---

Tool use: **read_file**

Read file: /Users/ahmedhaque/CodeWork/class-pro/app/layout.tsx

---

Tool use: **read_file**

Read file: /Users/ahmedhaque/CodeWork/class-pro/app/page.tsx

---

Tool use: **read_file**

Read file: /Users/ahmedhaque/CodeWork/class-pro/components/Navbar.tsx

---

<think><details><summary>Thought Process</summary>**Planning AI agent implementation**

I need to set up an AI agent that polls ClickHouse regularly, displaying prompts every 15 seconds. There are existing ClickHouse connections in API routes, so I’ll create a new backend route to query recent sentiment streams and generate prompts for OpenAI. On the frontend, I’ll design a small overlay component to show messages for users identified as 'teacher'. The component will fetch updates every 15 seconds, integrating seamlessly into the page or Navbar while managing status updates.
**Implementing API route and logic**

This task has several steps: I need to create an API route, query ClickHouse, craft messages, add an overlay component, and implement logic for updates every 15 seconds. I'll use `todo_write` to manage tasks and focus on coding edits with `apply_patch` or `edit_file`. I’ll set up a new API route under `app/api/ta-feedback/route.ts` that returns JSON with a message and possibly evidence. This route will query the last few minutes of student sentiment to identify when to prompt teachers for guidance.
**Designing sentiment prompts**

I need to provide thoughtful prompts that are two sentences or less, spaced every 15 seconds. The route will compute a snapshot from ClickHouse, focusing on the last two minutes of student sentiments, looking at averages and trends or possibly extremes for confidence scores. I’ll craft prompts using lists of low and high sentiment students, along with counts of messages. I’ll follow the existing code style for API calls and use the OpenAI key variable to generate these prompts based on my query results.
**Creating Teaching Assistant component**

I’m looking to compute the overall average and trend of student sentiments, possibly comparing the last minute to the previous minute. While I might skip the trend for simplicity, I can generate prompts from the lists of low and high sentiment students. The API route will return a structured object with low and high sentiment students, recent average confidence, and total messages. I’ll create a `TeachingAssistantAgent.tsx` component to be displayed for teachers, using a small modal positioned at the top-left and styled minimally, ensuring it fetches updates every 15 seconds.
**Implementing Teaching Assistant features**

I’m preparing to add the `<TeachingAssistantAgent userType={userType} />` component and will ensure it follows the existing Tailwind CSS styles. I’ll create a route file under `/app/api/ta-feedback/route.ts` while managing tasks systematically. Once I implement the route and component files, I’ll integrate them into `page.tsx` and perform lint tests on just the new files. If there’s no data, I should return a minimal default message. I’ll also set up a cleanup for the interval and implement the OpenAI call inside the API route to generate feedback prompts, making sure to follow security best practices while adhering to the code style guidelines.</details></think>

---

I'll create a server endpoint that queries ClickHouse and uses OpenAI to produce a 2-sentence teacher prompt, then add a client overlay component that polls it every 15 seconds and shows it at the top-left for teachers. Next, I'll wire the component into `app/page.tsx`.

---

Tool use: **todo_write**

## Todo List

- [-] Create API route to fetch recent sentiment and generate prompt
- [ ] Build top-left overlay component that polls API every 15s
- [ ] Integrate overlay into app/page.tsx for teacher view
- [ ] Run lints and fix any new issues

---

I'll add a new API route under `app/api/ta-agent/route.ts` that pulls last 2 minutes of `class_pro_confidence` from ClickHouse, summarizes key conditions, and asks OpenAI to produce a <=2 sentence prompt. Then I'll create a `components/TeachingAssistantOverlay.tsx` that polls this route every 15s and displays a small modal at top-left for teachers, and wire it into `app/page.tsx`.

---

Tool use: **apply_patch**

<details>
        <summary>Apply patch for /Users/ahmedhaque/CodeWork/class-pro/app/api/ta-agent/route.ts</summary>
      

```diff
*** Begin Patch
*** Add File: app/api/ta-agent/route.ts
+import { NextRequest, NextResponse } from 'next/server';
+import { createClient } from '@clickhouse/client';
+
+function getClient() {
+  const url = process.env.CLICKHOUSE_URL || 'https://d8irwr6qnd.us-east1.gcp.clickhouse.cloud:8443';
+  const username = process.env.CLICKHOUSE_USERNAME || 'default';
+  const password = process.env.CLICKHOUSE_PASSWORD || 'yABbAN.S3f0Og';
+  return createClient({ url, username, password });
+}
+
+export async function GET(request: NextRequest) {
+  try {
+    const { searchParams } = new URL(request.url);
+    const minutes = Math.max(1, Math.min(30, Number(searchParams.get('minutes')) || 2));
+
+    const client = getClient();
+
+    const query = `
+      SELECT
+        toStartOfMinute(ts) as bucket,
+        avg(confidence) as avg_conf,
+        countIf(student != 'You') as student_msgs,
+        countIf(student != 'You' AND positionCaseInsensitive(text, '?') > 0) as student_questions,
+        groupArrayIf(student, student != 'You') as students,
+        groupArrayIf(confidence, student != 'You') as confidences
+      FROM class_pro_confidence
+      WHERE ts >= now() - INTERVAL ${minutes} MINUTE
+      GROUP BY bucket
+      ORDER BY bucket DESC
+      LIMIT 3
+    `;
+
+    const rows = await client.query({ query, format: 'JSONEachRow' });
+    const data = await rows.json<any[]>();
+
+    // Compute quick heuristics
+    const latest = data[0] || null;
+    const avgConf = Number(latest?.avg_conf ?? 3);
+    const totalQuestions = data.reduce((sum, r) => sum + Number(r.student_questions || 0), 0);
+
+    // Identify potential students to call on: highest and lowest confidence in window
+    const names: string[] = [];
+    const confs: number[] = [];
+    for (const r of data) {
+      const s = (r.students || []) as string[];
+      const c = (r.confidences || []) as number[];
+      for (let i = 0; i < Math.min(s.length, c.length); i++) {
+        names.push(s[i]);
+        confs.push(Number(c[i]));
+      }
+    }
+
+    const byStudent: Record<string, { max: number; min: number; last: number } > = {};
+    names.forEach((n, i) => {
+      const v = confs[i] ?? 3;
+      const cur = byStudent[n] || { max: v, min: v, last: v };
+      cur.max = Math.max(cur.max, v);
+      cur.min = Math.min(cur.min, v);
+      cur.last = v;
+      byStudent[n] = cur;
+    });
+
+    const entries = Object.entries(byStudent);
+    entries.sort((a, b) => (b[1].last - a[1].last));
+    const top = entries[0]?.[0];
+    entries.sort((a, b) => (a[1].last - b[1].last));
+    const bottom = entries[0]?.[0];
+
+    const apiKey = process.env.OPENAI_API_KEY || process.env.OPENAI_HACKATHON_KEY;
+
+    const system = `You are playing the role of assistant Teaching Assistant. Your role is to review the stream of student sentiment scores in the chat interface and call out cases where the instructor should slow down or re-review a subject. It should also call out cases where there are students who have strong sentiment that might be worth calling on to answer questions in class to create engagement or to encourage a student with a weaker student to see if they have questions. It should provide thoughtful prompts of no more than 2 sentences at a time. It should space out its feedback such that it provides feedback every 15 seconds.`;
+
+    const summary = {
+      avgConfidence: Number.isFinite(avgConf) ? Number(avgConf.toFixed(2)) : 3,
+      totalQuestions,
+      highConfidenceStudent: top || null,
+      lowConfidenceStudent: bottom || null,
+    };
+
+    let suggestion = '';
+    if (apiKey) {
+      const user = `Recent class pulse summary: ${JSON.stringify(summary)}\nProvide a <=2 sentence suggestion to the instructor right now.`;
+      const resp = await fetch('https://api.openai.com/v1/chat/completions', {
+        method: 'POST',
+        headers: {
+          'Content-Type': 'application/json',
+          'Authorization': `Bearer ${apiKey}`,
+        },
+        body: JSON.stringify({
+          model: 'gpt-4o-mini',
+          messages: [
+            { role: 'system', content: system },
+            { role: 'user', content: user },
+          ],
+          temperature: 0.3,
+          max_tokens: 120,
+        }),
+      });
+
+      if (resp.ok) {
+        const j = await resp.json();
+        suggestion = j?.choices?.[0]?.message?.content?.trim() || '';
+      }
+    }
+
+    // Fallback suggestion
+    if (!suggestion) {
+      if (summary.avgConfidence < 3) {
+        suggestion = 'Confidence is trending low. Consider pausing to recap key points and invite questions.';
+      } else if (summary.totalQuestions > 0) {
+        suggestion = 'There are questions coming in; take a moment to address them and reinforce understanding.';
+      } else if (summary.highConfidenceStudent) {
+        suggestion = `Ask ${summary.highConfidenceStudent} to share a quick insight to boost engagement.`;
+      } else {
+        suggestion = 'Maintain the pace but check in briefly to confirm understanding across the room.';
+      }
+    }
+
+    return NextResponse.json({ ok: true, data: { summary, suggestion } });
+  } catch (e: any) {
+    console.error('ta-agent error', e);
+    return NextResponse.json({ ok: false, error: e?.message || 'Unknown error' }, { status: 500 });
+  }
+}
+
*** End Patch
```

---

Tool use: **todo_write**

## Todo List

- [x] Create API route to fetch recent sentiment and generate prompt
- [-] Build top-left overlay component that polls API every 15s
- [ ] Integrate overlay into app/page.tsx for teacher view
- [ ] Run lints and fix any new issues

---

Tool use: **apply_patch**

<details>
        <summary>Apply patch for /Users/ahmedhaque/CodeWork/class-pro/components/TeachingAssistantOverlay.tsx</summary>
      

```diff
*** Begin Patch
*** Add File: components/TeachingAssistantOverlay.tsx
+'use client';
+
+import { useEffect, useRef, useState } from 'react';
+
+interface TeachingAssistantOverlayProps {
+  userType: 'teacher' | 'student';
+}
+
+export default function TeachingAssistantOverlay({ userType }: TeachingAssistantOverlayProps) {
+  const [message, setMessage] = useState<string>('');
+  const [visible, setVisible] = useState<boolean>(false);
+  const timerRef = useRef<NodeJS.Timeout | null>(null);
+
+  async function fetchSuggestion() {
+    try {
+      const resp = await fetch('/api/ta-agent?minutes=2', { cache: 'no-store' });
+      if (!resp.ok) return;
+      const data = await resp.json();
+      const suggestion: string | undefined = data?.data?.suggestion;
+      if (suggestion && typeof suggestion === 'string') {
+        setMessage(suggestion);
+        setVisible(true);
+        // Auto-hide after 8s to prevent clutter
+        setTimeout(() => setVisible(false), 8000);
+      }
+    } catch (e) {
+      // ignore
+    }
+  }
+
+  useEffect(() => {
+    if (userType !== 'teacher') return;
+
+    // Fetch immediately, then every 15s
+    fetchSuggestion();
+    timerRef.current = setInterval(fetchSuggestion, 15000);
+    return () => {
+      if (timerRef.current) clearInterval(timerRef.current);
+    };
+  }, [userType]);
+
+  if (userType !== 'teacher' || !visible || !message) return null;
+
+  return (
+    <div className="fixed top-4 left-4 z-50">
+      <div className="max-w-[320px] bg-white/95 backdrop-blur border border-[#E5E5E5] shadow-[0_6px_20px_rgba(0,0,0,0.12)] rounded-lg p-3">
+        <div className="text-[11px] uppercase tracking-wide text-[#6B6F76] mb-1 font-semibold">Teaching Assistant</div>
+        <div className="text-[13px] text-[#0D0D0D] leading-snug">{message}</div>
+      </div>
+    </div>
+  );
+}
+
*** End Patch
```

---

Tool use: **apply_patch**

<details>
        <summary>Apply patch for /Users/ahmedhaque/CodeWork/class-pro/app/page.tsx</summary>
      

```diff
*** Begin Patch
*** Update File: app/page.tsx
@@
 import Navbar from '@/components/Navbar';
 import VideoSection from '@/components/VideoSection';
 import ChatInterface from '@/components/ChatInterface';
+import TeachingAssistantOverlay from '@/components/TeachingAssistantOverlay';
@@
       <Navbar userType={userType} onUserTypeChange={setUserType} />
 
       {/* Main Content with generous spacing */}
       <main className="flex-1 p-8 max-w-[1600px] mx-auto w-full">
+        <TeachingAssistantOverlay userType={userType} />
         {/* Video and Chat Section - clean layout with breathing room */}
         <div className="grid grid-cols-1 lg:grid-cols-[1fr_400px] gap-6 h-[calc(100vh-120px)] min-h-[600px]">
           <VideoSection />
           <ChatInterface userType={userType} />
         </div>
       </main>
*** End Patch
```

---

Tool use: **read_lints**

<details>
          <summary>Read lints for 3 files</summary>
      
Lint paths:

- `/Users/ahmedhaque/CodeWork/class-pro/app/api/ta-agent/route.ts`
- `/Users/ahmedhaque/CodeWork/class-pro/components/TeachingAssistantOverlay.tsx`
- `/Users/ahmedhaque/CodeWork/class-pro/app/page.tsx`

Lint results

Lint errors for `app/page.tsx`


| Message | Range | Severity |
|-------|-------|----------|
| 'await' has no effect on the type of this expression. | 51:15-51:52 | DIAGNOSTIC_SEVERITY_HINT |


</details>

---

Tool use: **todo_write**

## Todo List

- [x] Create API route to fetch recent sentiment and generate prompt
- [x] Build top-left overlay component that polls API every 15s
- [x] Integrate overlay into app/page.tsx for teacher view
- [ ] Run lints and fix any new issues

---

Tool use: **todo_write**

## Todo List

- [x] Create API route to fetch recent sentiment and generate prompt
- [x] Build top-left overlay component that polls API every 15s
- [x] Integrate overlay into app/page.tsx for teacher view
- [x] Run lints and fix any new issues

---

Plan:
- Add API `GET /api/ta-agent` that queries ClickHouse for recent confidence metrics and asks OpenAI to generate ≤2 sentence guidance based on your provided TA prompt.
- Add `TeachingAssistantOverlay` that polls the endpoint every 15s and shows a lightweight modal at top-left for teachers.
- Wire overlay into `app/page.tsx` so it only renders for teachers.

Code:
- New API route: `app/api/ta-agent/route.ts`
```startLine:endLine:app/api/ta-agent/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@clickhouse/client';

function getClient() {
  const url = process.env.CLICKHOUSE_URL || 'https://d8irwr6qnd.us-east1.gcp.clickhouse.cloud:8443';
  const username = process.env.CLICKHOUSE_USERNAME || 'default';
  const password = process.env.CLICKHOUSE_PASSWORD || 'yABbAN.S3f0Og';
  return createClient({ url, username, password });
}

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const minutes = Math.max(1, Math.min(30, Number(searchParams.get('minutes')) || 2));

    const client = getClient();

    const query = `
      SELECT
        toStartOfMinute(ts) as bucket,
        avg(confidence) as avg_conf,
        countIf(student != 'You') as student_msgs,
        countIf(student != 'You' AND positionCaseInsensitive(text, '?') > 0) as student_questions,
        groupArrayIf(student, student != 'You') as students,
        groupArrayIf(confidence, student != 'You') as confidences
      FROM class_pro_confidence
      WHERE ts >= now() - INTERVAL ${minutes} MINUTE
      GROUP BY bucket
      ORDER BY bucket DESC
      LIMIT 3
    `;

    const rows = await client.query({ query, format: 'JSONEachRow' });
    const data = await rows.json<any[]>();

    const latest = data[0] || null;
    const avgConf = Number(latest?.avg_conf ?? 3);
    const totalQuestions = data.reduce((sum, r) => sum + Number(r.student_questions || 0), 0);

    const names: string[] = [];
    const confs: number[] = [];
    for (const r of data) {
      const s = (r.students || []) as string[];
      const c = (r.confidences || []) as number[];
      for (let i = 0; i < Math.min(s.length, c.length); i++) {
        names.push(s[i]);
        confs.push(Number(c[i]));
      }
    }

    const byStudent: Record<string, { max: number; min: number; last: number } > = {};
    names.forEach((n, i) => {
      const v = confs[i] ?? 3;
      const cur = byStudent[n] || { max: v, min: v, last: v };
      cur.max = Math.max(cur.max, v);
      cur.min = Math.min(cur.min, v);
      cur.last = v;
      byStudent[n] = cur;
    });

    const entries = Object.entries(byStudent);
    entries.sort((a, b) => (b[1].last - a[1].last));
    const top = entries[0]?.[0];
    entries.sort((a, b) => (a[1].last - b[1].last));
    const bottom = entries[0]?.[0];

    const apiKey = process.env.OPENAI_API_KEY || process.env.OPENAI_HACKATHON_KEY;

    const system = `You are playing the role of assistant Teaching Assistant. Your role is to review the stream of student sentiment scores in the chat interface and call out cases where the instructor should slow down or re-review a subject. It should also call out cases where there are students who have strong sentiment that might be worth calling on to answer questions in class to create engagement or to encourage a student with a weaker student to see if they have questions. It should provide thoughtful prompts of no more than 2 sentences at a time. It should space out its feedback such that it provides feedback every 15 seconds.`;

    const summary = {
      avgConfidence: Number.isFinite(avgConf) ? Number(avgConf.toFixed(2)) : 3,
      totalQuestions,
      highConfidenceStudent: top || null,
      lowConfidenceStudent: bottom || null,
    };

    let suggestion = '';
    if (apiKey) {
      const user = `Recent class pulse summary: ${JSON.stringify(summary)}\nProvide a <=2 sentence suggestion to the instructor right now.`;
      const resp = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'system', content: system },
            { role: 'user', content: user },
          ],
          temperature: 0.3,
          max_tokens: 120,
        }),
      });

      if (resp.ok) {
        const j = await resp.json();
        suggestion = j?.choices?.[0]?.message?.content?.trim() || '';
      }
    }

    if (!suggestion) {
      if (summary.avgConfidence < 3) {
        suggestion = 'Confidence is trending low. Consider pausing to recap key points and invite questions.';
      } else if (summary.totalQuestions > 0) {
        suggestion = 'There are questions coming in; take a moment to address them and reinforce understanding.';
      } else if (summary.highConfidenceStudent) {
        suggestion = `Ask ${summary.highConfidenceStudent} to share a quick insight to boost engagement.`;
      } else {
        suggestion = 'Maintain the pace but check in briefly to confirm understanding across the room.';
      }
    }

    return NextResponse.json({ ok: true, data: { summary, suggestion } });
  } catch (e: any) {
    console.error('ta-agent error', e);
    return NextResponse.json({ ok: false, error: e?.message || 'Unknown error' }, { status: 500 });
  }
}
```

- New component: `components/TeachingAssistantOverlay.tsx`
```startLine:endLine:components/TeachingAssistantOverlay.tsx
'use client';

import { useEffect, useRef, useState } from 'react';

interface TeachingAssistantOverlayProps {
  userType: 'teacher' | 'student';
}

export default function TeachingAssistantOverlay({ userType }: TeachingAssistantOverlayProps) {
  const [message, setMessage] = useState<string>('');
  const [visible, setVisible] = useState<boolean>(false);
  const timerRef = useRef<NodeJS.Timeout | null>(null);

  async function fetchSuggestion() {
    try {
      const resp = await fetch('/api/ta-agent?minutes=2', { cache: 'no-store' });
      if (!resp.ok) return;
      const data = await resp.json();
      const suggestion: string | undefined = data?.data?.suggestion;
      if (suggestion && typeof suggestion === 'string') {
        setMessage(suggestion);
        setVisible(true);
        setTimeout(() => setVisible(false), 8000);
      }
    } catch (e) {
      // ignore
    }
  }

  useEffect(() => {
    if (userType !== 'teacher') return;

    fetchSuggestion();
    timerRef.current = setInterval(fetchSuggestion, 15000);
    return () => {
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, [userType]);

  if (userType !== 'teacher' || !visible || !message) return null;

  return (
    <div className="fixed top-4 left-4 z-50">
      <div className="max-w-[320px] bg-white/95 backdrop-blur border border-[#E5E5E5] shadow-[0_6px_20px_rgba(0,0,0,0.12)] rounded-lg p-3">
        <div className="text-[11px] uppercase tracking-wide text-[#6B6F76] mb-1 font-semibold">Teaching Assistant</div>
        <div className="text-[13px] text-[#0D0D0D] leading-snug">{message}</div>
      </div>
    </div>
  );
}
```

- Wire-in overlay in `app/page.tsx`
```startLine:endLine:app/page.tsx
import Navbar from '@/components/Navbar';
import VideoSection from '@/components/VideoSection';
import ChatInterface from '@/components/ChatInterface';
import TeachingAssistantOverlay from '@/components/TeachingAssistantOverlay';
...
      <Navbar userType={userType} onUserTypeChange={setUserType} />

      {/* Main Content with generous spacing */}
      <main className="flex-1 p-8 max-w-[1600px] mx-auto w-full">
        <TeachingAssistantOverlay userType={userType} />
        {/* Video and Chat Section - clean layout with breathing room */}
        <div className="grid grid-cols-1 lg:grid-cols-[1fr_400px] gap-6 h-[calc(100vh-120px)] min-h-[600px]">
          <VideoSection />
          <ChatInterface userType={userType} />
        </div>
      </main>
```

Steps taken:
- Created `GET /api/ta-agent` to aggregate last 2 minutes of confidence, identify high/low students, and request a concise suggestion from OpenAI using your TA prompt, with safe fallbacks.
- Added `TeachingAssistantOverlay` that polls every 15s, auto-hides each suggestion after 8s, and only renders for `userType === 'teacher'`.
- Integrated overlay into `app/page.tsx`.
- Ran lints; no issues found.

I added a lightweight polling agent with OpenAI guidance based on recent ClickHouse pulse data, and a top-left modal that surfaces suggestions to teachers every 15 seconds.

---

